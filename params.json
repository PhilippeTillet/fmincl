{"name":"UMinTL","tagline":"Unconstrained Minimization Template Library","body":"UMinTL\r\n======\r\n\r\nThis project is a generic unconstrained minimization library relying heavily on template metaprogramming.\r\n\r\n##Features [ UMinTL 1.0 ]\r\n\r\n* Compatible with **any** Linear Algebra backend\r\n\r\nThe linear algebra routines are well separated from the algorithm implementations.\r\nYou can plug your own linear algebra backend into the optimization procedure. This backend should just include a few typedefs, linear algebra routine and procedures to allocate/delete a Vector/Matrix.\r\nFor now, backends for BLAS (tested on mwblas provided by matlab), cBLAS (tested on OpenBlas) and Eigen are supported. CuBlas or ViennaCL backends should also work out-of-the box, but are not provided, yet.\r\n\r\n* **Lightweight**, **portable** and **headers-only**\r\n\r\nUMinTL is C++03-compliant and does not require any external package.\r\n\r\n* An **extendable** library\r\n\r\nUMinTL relies on C++ templates. You may therefore write your own stopping criterion (eg a cross-validation error if you're doing machine learning). More experienced user may also write their own restarting condition for the conjugate gradient, or their own update direction.\r\n\r\n* A **clear** interface\r\n\r\nUMinTL provides a clear C++ API, relying on functors rather than functions..\r\n\r\n* A **robust** package\r\n\r\nUMinTL was extensively tested on the test suite described in \"Testing Unconstrained Optimization Software\" (JJ Moré and al.). However, I am aware that it will never be robust enough. If the procedure fails on your particular problem, please *report*.\r\n\r\n* **Efficient* optimization routines\r\n\r\nThe library supports BFGS, L-BFGS, and Nonlinear Conjugate Gradient (Several updates and restart procedures).\r\nThe line-search is done using the strong wolfe-powell conditions.\r\nThe implementations are inspired from the renowed minfunc package for MATLAB (www.di.ens.fr/~mschmidt/Software/minFunc.html‎)\r\n\r\n\r\n## Incoming Features [ UMinTL 1.1 ]\r\n\r\n* Hessian-free optimization\r\n\r\nHessian-free optimization has shown encouraging results in the Machine Learning litterature. It is a fundamental building block of the unconstrained optimization framework, which should absolutely be provided.\r\n\r\n* Mini-batch / Stochastic and Semi-Stochastic procedures\r\n\r\nFor now, UMinTL only provides batch methods. Mini-Batch/Stochastic/Semi-stochastic approaches should also be provided.\r\n\r\n* Supported GPU backend(s)\r\n\r\nAt least ViennaCL backend should be provided, in order to carry out the optimization process on heterogeneous devices, or to avoid CPU-to-GPU transfers (when optimizing on the CPU and evaluating the objective function on the GPU)\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}